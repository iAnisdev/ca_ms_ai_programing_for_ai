{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the dotenv package to load the environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get the environment variables and store them in variables\n",
    "api_key = os.getenv('API_KEY')\n",
    "base_url = os.getenv('BASE_URL')\n",
    "\n",
    "\n",
    "# define the start and end date for the historical data\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2020-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2024-11-12', 'title': 'NGC 6888: The Crescent Nebula', 'url': 'https://apod.nasa.gov/apod/image/2411/Ngc6888Hoo_Aro_960.jpg', 'explanation': \"How was the Crescent Nebula created?  Looking like an emerging space cocoon, the Crescent Nebula, visible in the center of the featured image, was created by the brightest star in its center.  A leading progenitor hypothesis has the Crescent Nebula beginning to form about 250,000 years ago.  At that time, the massive central star had evolved to become a Wolf-Rayet star (WR 136), shedding its outer envelope in a strong stellar wind, ejecting the equivalent of our Sun's mass every 10,000 years.  This wind impacted surrounding gas left over from a previous phase, compacting it into a series of complex shells, and lighting it up.  The Crescent Nebula, also known as NGC 6888, lies about 4,700 light-years away in the constellation of Cygnus.  Star WR 136 will probably undergo a supernova explosion sometime in the next million years.   Jigsaw Challenge: Astronomy Puzzle of the Day\", 'media_type': 'image'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import date , timedelta\n",
    "\n",
    "def get_apod_data(api_key, date):\n",
    "    url = f\"{base_url}/planetary/apod?api_key={api_key}&date={date}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        # check if the response is successful and raise an exception incase of an error\n",
    "        response.raise_for_status()\n",
    "        # parse the JSON response\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"date\": data.get(\"date\"),\n",
    "            \"title\": data.get(\"title\"),\n",
    "            \"url\": data.get(\"url\"),\n",
    "            \"explanation\": data.get(\"explanation\"),\n",
    "            \"media_type\": data.get(\"media_type\")\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {date}: {e}\")\n",
    "    except KeyError:\n",
    "        print(\"Unexpected response format\")\n",
    "\n",
    "# Get today's date  and fetch the data for today from the API to test the function\n",
    "today = date.today()\n",
    "today_data = get_apod_data(api_key, today)\n",
    "\n",
    "print(today_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.790s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x10e6e4c50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the response data by checking if the response is a dictionary and contains the expected keys and values \n",
    "import unittest\n",
    "\n",
    "class TestGetApodData(unittest.TestCase):\n",
    "    def test_get_apod_data(self):\n",
    "        data = get_apod_data(api_key, date.today())\n",
    "        self.assertIsInstance(data, dict)\n",
    "        self.assertIn(\"date\", data)\n",
    "        self.assertIn(\"title\", data)\n",
    "        self.assertIn(\"url\", data)\n",
    "        self.assertIn(\"explanation\", data)\n",
    "        self.assertIn(\"media_type\", data)\n",
    "    \n",
    "# Run the test\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Function to fetch APOD data for multiple dates within a range\n",
    "def fetch_multiple_apod_data(api_key, start_date, end_date):\n",
    "    current_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    apod_data = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "        # Fetch data for the current date\n",
    "        data = get_apod_data(api_key, date_str)\n",
    "        if data:\n",
    "            print(f\"Fetched data for {date_str}\")\n",
    "            apod_data.append(data)\n",
    "        # Move to the next date\n",
    "        current_date += timedelta(days=1)\n",
    "        # Delay to respect API rate limits\n",
    "        time.sleep(1)  \n",
    "\n",
    "    return apod_data\n",
    "\n",
    "apod_data = fetch_multiple_apod_data(api_key, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better approach the fetch the data for multiple dates using start_date and end_date as query parameters in the API URL\n",
    "\n",
    "def get_range_apod_data(api_key, start_date , end_date):\n",
    "    url = f\"{base_url}/planetary/apod?api_key={api_key}&start_date={start_date}&end_date={end_date}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        formatted_data = []\n",
    "        for item in data:\n",
    "            formatted_data.append({\n",
    "                \"date\": item.get(\"date\"),\n",
    "                \"title\": item.get(\"title\"),\n",
    "                \"url\": item.get(\"url\"),\n",
    "                \"explanation\": item.get(\"explanation\"),\n",
    "                \"media_type\": item.get(\"media_type\")\n",
    "            })\n",
    "        return formatted_data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for the range {start_date} to {end_date}: {e}\")\n",
    "    except KeyError:\n",
    "        print(\"Unexpected response format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def save_to_json(data, filename='apod_data.json'):\n",
    "    try:\n",
    "        # Verify if the data is a JSON-serializable list\n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError(\"Data should be a list\")\n",
    "\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(filename):\n",
    "            # If the file does not exist, create it and add the data\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(data, file, indent=4)\n",
    "                file.write(\"\\n\")\n",
    "            return\n",
    "        \n",
    "        # If the file exists, check if it contains any data\n",
    "        with open(filename, 'r+') as file:\n",
    "            if os.stat(filename).st_size == 0:\n",
    "                # If the file is empty, add the data directly\n",
    "                json.dump(data, file, indent=4)\n",
    "                file.write(\"\\n\")\n",
    "            else:\n",
    "                # If the file has data, load existing data, concatenate with new data\n",
    "                file.seek(0)\n",
    "                existing_data = json.load(file)\n",
    "                \n",
    "                # Ensure existing data is a list\n",
    "                if not isinstance(existing_data, list):\n",
    "                    raise ValueError(\"Existing file data is not in list format\")\n",
    "\n",
    "                # Concatenate existing data with the new data\n",
    "                updated_data = existing_data + data\n",
    "                \n",
    "                # Write the concatenated data back to the file\n",
    "                file.seek(0)\n",
    "                file.truncate(0)\n",
    "                json.dump(updated_data, file, indent=4)\n",
    "                file.write(\"\\n\")\n",
    "                \n",
    "    except ValueError as ve:\n",
    "        print(f\"Data validation error: {ve}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file {filename}: {e}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON from file {filename}. Ensure the file format is correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for 15 dates\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_save_apod_data(api_key, start_date, end_date):\n",
    "    # using the get_range_apod_data function for better performance and to avoid rate limits\n",
    "    range_data = get_range_apod_data(api_key, start_date, end_date)\n",
    "    # to test the loop function, uncomment the line below and comment the line above\n",
    "    # range_data = fetch_multiple_apod_data(api_key, start_date, end_date)\n",
    "    if range_data:\n",
    "        print(f\"Fetched data for {len(range_data)} dates\")\n",
    "        # Save the data to a JSON file with the default filename\n",
    "        save_to_json(range_data) \n",
    "\n",
    "\n",
    "fetch_and_save_apod_data(api_key, start_date, end_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
